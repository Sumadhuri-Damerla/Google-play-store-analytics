---
title: "Google Play Store Analytics"
author: "Sumadhuri Damerla,Shaoor Jan,Ashjan Khan"
subtitle: Final Report
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
  pdf_document:
    df_print: paged
    fig_caption: yes
    number_sections: yes
    toc: yes
    toc_depth: '2'
---
```{r global_options, include=FALSE}
# global options for figure width and height
knitr::opts_chunk$set(
  fig.width = 10,
  fig.height = 10,
  echo = FALSE,
  warning = FALSE,
  message = FALSE
)

```

\newpage

# Introduction to the dataset  
## Data source
The data source used for this analysis is the *2018 google play store*(https://www.kaggle.com/lava18/google-play-store-apps) collected from Kaggle.

## Description of the dataset
The dataset is a collection of web-scraped data of 10,000 apps from Google Play Store. Google Play Store originally referred as the Android Market, is Google's official store and portal for Android apps, games and other content for Android-powered phone, tablet or Android TV device. As of May 2017, it has over two billion monthly active users, the largest installed base of any operating system, and as of January 2020, the Google Play Store features over 2.9 million apps[13].

The variables of the dataset are as follows:

1)	App (Name) – Name/Title of the application
2)	Category (App)- Category/Domain to which  the app belongs to
3)	Rating (App)- Overall user rating of the app
4)	Reviews (User)- Number of user reviews for the app 
5)	Size (App)- Space or memory that the app takes up 
6)	Installs (App)- Number of user downloads/installs 
7)	Type (Free/Paid)-Apps may be free or paid depending on the developer’s choice
8)	Price (App)-Price of the app if not free
9)	Content Rating -  Age group the app is based off at - Children / Mature 21+ / Adult
10)	Genres (Detailed Category)- An app can belong to multiple genres, For eg, a musical family game will belong to Music, Game, Family genres.
11)	Last Updated (App)- Date when the app was last updated on Play Store 
12)	Current Version (App)- Current version of the app available on Play Store 
13)	Android Version (Support) – minimum version of android it takes to have the app on the device


# Purpose of the project
 + The aim of our project is to find out if we can predict ratings of an app based on different variables and we intend to summarise the different factors that influence the success of an app.These analysis might also help the developer community to build more successful apps by taking accurate data-based decisions, and focusing on those aspects of applications that matters most.

 + Also,since this is the first time we are doing data analysis using R, it is a fun way to learn and  to strengthen the concepts learned during the course by taking a hands-on approach.

# Intended audience of the project
 + We believe there's a diverse set of audience who might be interested in our project. As of Febraury 2020, 73.3% of the mobile operating system market share belongs to Android devices[11]. This large community consists of the general public who use android devices and appstore,the developer community and anyone who wants to understand how the app market works.

 + This project is primarily intended for the growing developer community. It will help them make data backed decisions before launching their application. Besides developers, it is also helpful for tech journalists, Google Play Store users or any other interested party. 


```{r load-libraries}
library(tidyverse)
library(dplyr)
library(stringr)
require(ggExtra) # For marginal graphs
require(GGally) #for correlation plot
library(rpart)
library(moderndive)
library(ggpubr)
library(knitr)
library(kableExtra)
theme_set(theme_light())
set.seed(123)
```

```{r custom-color-pallete}
# reference: https://drsimonj.svbtle.com/creating-corporate-colour-palettes-for-ggplot2

custom_colors <- c(
  `red`             = "#d11141",
  `blueish green`   = "#009E73",
  `blue`            = "#0072B2",
  `sky blue`        = "#56B4E9",
  `orange`          = "#E69F00",
  `vermillion`      = "#D55E00",
  `yellow`          = "#009E73",
  `grey`            = "#999999",
  `reddish purple`  = "#CC79A7"
)

custom_cols <- function(...) {
  cols <- c(...)
  
  if (is.null(cols))
    return (custom_colors)
  
  custom_colors[cols]
}

custom_palettes <- list(
  `main`  = custom_cols("blue", "green", "yellow"),
  
  `cool`  = custom_cols("blue", "green"),
  
  `hot`   = custom_cols("yellow", "orange", "red"),
  
  `mixed` = custom_cols("blue", "green", "yellow", "orange", "red"),
  
  `grey`  = custom_cols("light grey", "dark grey")
)

custom_pal <- function(palette = "main",
                       reverse = FALSE,
                       ...) {
  pal <- custom_palettes[[palette]]
  
  if (reverse)
    pal <- rev(pal)
  
  colorRampPalette(pal, ...)
}

scale_color <-
  function(palette = "main",
           discrete = TRUE,
           reverse = FALSE,
           ...) {
    pal <- custom_pal(palette = palette, reverse = reverse)
    
    if (discrete) {
      discrete_scale("colour", paste0("drsimonj_", palette), palette = pal, ...)
    } else {
      scale_color_gradientn(colours = pal(256), ...)
    }
  }

scale_fill <-
  function(palette = "main",
           discrete = TRUE,
           reverse = FALSE,
           ...) {
    pal <- custom_pal(palette = palette, reverse = reverse)
    
    if (discrete) {
      discrete_scale("fill", paste0("drsimonj_", palette), palette = pal, ...)
    } else {
      scale_fill_gradientn(colours = pal(256), ...)
    }
  }
```

```{r loading-data}
clean_play_store <-
  read_csv("data/tidyplaystore.csv") #read_csv returns a dataframe
```

# Exploratory Data Analysis to find factors for success of an app
Generally, the most successful apps have high ratings and high installs.To look at which app makes it to the top, we consider ratings and installs, so we explore these to find any relationship or trends

## Rating column in depth 
### Distribution of rating  
```{r rating-density-plot}
#Density plot of rating
clean_play_store %>%
  ggplot(aes(x = rating)) +
  geom_density(aes(fill = factor(types)), alpha = 0.5) + #types correspond to paid/free
  #adding title, subtitle and labels
  labs(
    title = "Density plot",
    subtitle = "App Rating grouped by types",
    y = "Values",
    x = "Rating",
    caption = "Source: google play store dataset",
    fill = "#Types"
  ) +
  theme(axis.text.x = element_text(vjust = 0.5))
```

**Finding: ** We observed that there are minimal number of apps with low ratings whereas most of the apps have ratings between 3-5.

\newpage

## Correlogram plots  
Firstly, we plot correlograms of rating column versus different columns to find relationships between the variables. Correlograms are useful to understand the relationship between different numerical variables. If the correlogram index is 1, it means that the variables are directly proportional to each other.  
````{r correlogram-plot, out.width="50%", fig.width=3, fig.height=2.5,fig.show='hold',fig.align='center'}

#--code below:correlogram plot of rating vs reviews--
clean_play_store$Reviews <-
  log(clean_play_store$reviews) #transforming the reviews value to logarithmic values

clean_play_store %>%
  select(rating, Reviews) %>%
  ggpairs(mapping = ggplot2::aes(color = "types")) +
  labs(subtitle = "Rating vs Reviews",
       caption = "Source: google play store dataset")

#--code below:correlogram plot of rating vs size--
clean_play_store %>%
  select(rating, size_mb) %>%
  ggpairs(mapping = ggplot2::aes(color = "types")) +
  labs(subtitle = "Rating vs Size (MB)",
       caption = "Source: google play store dataset")

#--code below:correlogram plot of rating vs reviews--
clean_play_store$Installs <-
  log(clean_play_store$installs) #transforming the installs values to logarithmic values

clean_play_store %>%
  select(rating, Installs) %>%
  ggpairs(mapping = ggplot2::aes(color = "types")) +
  labs(subtitle = "Rating vs Installs",
       caption = "Source: google play store dataset")

#--code below:correlogram plot of rating vs types--
clean_play_store$types <-
  as.factor(clean_play_store$types) #changing the types column to factor

clean_play_store %>%
  select(rating, types) %>%
  ggpairs(mapping = ggplot2::aes(color = "types")) +
  labs(subtitle = "Rating vs Types",
       caption = "Source: google play store dataset")
```

**Finding:**  
 * Each correlation index talks about the relationship between plotted columns. If the index is 1, it means they have linear relationship  
 * Each plot on the diagonal refers to the density plot of the respective column  
 * We can observe that there is no significant linear relationship between rating and the plotted numerical variables.  


### Plot of reviews vs app ratings
``` {r review-rating-plot}
#Dot plot to understand ratings vs reviews
ggplot(data = clean_play_store) +
  geom_point(mapping = aes(x = rating, y = reviews, col = types)) +
  scale_color(palette = "hot") + #custom color palette 
  scale_y_continuous(trans = 'log10', labels = scales::comma) + #logarithmic transformation of y-axis
  labs(
    title = "Dot plot",
    subtitle = "Android App Ratings vs Number of Reviews",
    x = "Rating from 1 to 5 stars",
    y = "Number of Reviews",
    caption = "Source: google play store dataset",
    fill = "Types"
  ) +
  theme(legend.title = element_text(hjust = 0.5, face = "bold", size = 10))
```


**Finding:** We can observe that the number of reviews influence the ratings. Generally, as the number of reviews increase, the rating is higher.


### App rating vs category  
```{r rating-category-plot}
#To check the relationship between category and rating, we plotted a box plot with rating on y-axis and category on x-axis.
clean_play_store %>%
  ggplot(aes(x = reorder(category, rating), y = rating)) +
  geom_boxplot(aes(fill = category)) +
  scale_fill(palette = "main") +
  labs(
    title = "Boxplot",
    subtitle = "Android App Ratings by category",
    x = "Category",
    y = "Rating",
    caption = "Source: google play store dataset"
  ) +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = "None") +
  coord_flip() #coordinate flip to view the graph better
```

**Finding:** We observed that some categories like TOOLS, FAMILY, FINANCE and LIFESTYLE and a great majority of applications fall below first quartile. Thus, even though the median rating is high, the deviation from median is significant.

\newpage

### Distribution of rating for 8 categories with the largest numbers of apps   
We look at the distribution of rating across different categories. We chose 8 categories with the largest number of applications.  

```{r avg-rating-distributionplot}
# Distribution of rating for 8 categories with the largest numbers of apps
clean_play_store %>%
  #adding a filter to chose top 8 categories
  filter(
    category == c(
      "FAMILY",
      "GAME",
      "TOOLS",
      "MEDICAL",
      "BUSINESS",
      "PRODUCTIVITY",
      "FINANCE",
      "COMMUNICATION",
      "SPORTS"
    )
  ) %>%
  #facet plot of rating
  ggplot(aes(x = rating)) +
  geom_bar(fill = custom_cols("blueish green"), na.rm = TRUE) +
  facet_wrap(~ category,
             ncol = 4,
             nrow = 4,
             shrink = TRUE) +
  labs(
    title = "Facet plot",
    subtitle = "Distribution of rating for 8 categories with the highest numbers of apps",
    x = "Rating",
    y = "Count",
    caption = "Source: google play store dataset"
  )
```

**Finding:** The distribution of rating varies significantly across each categories.  

\newpage

### Average rating per category 
In the previous graph, we observed that the distribution of rating varies significantly with different categories. This plot is to find the average rating per category.

```{r avgrating-categoryplot}
# Average rating per category
clean_play_store %>%
  #select category and rating columns
  select(c("category", "rating")) %>%
  #grouping the dataset by category
  group_by(category) %>%
  summarise(rating = mean(rating, na.rm = TRUE)) %>%
  #bar plot of the average rating and category
  ggplot(aes(x = reorder(category, -rating) , rating)) +
  geom_col(width = 0.5, fill = custom_cols("sky blue")) +
  #title
  ggtitle("Average Rating Per Category") +
  #Adding labels
  labs(
    title = "Bar Chart",
    subtitle = "Average Rating Per Category",
    y = "Rating",
    x = "Category",
    caption = "Source: google play store dataset"
  ) +
  #adding the theme
  theme(axis.text.x = element_text(angle = 90),
        legend.position = "none")
```

**Finding:** We observed that the average rating per category is not very different for each category. The "EVENTS" category still has the highest average rating, and "DATING" category has the least average rating. 

\newpage

### Size and rating  
The below plot is to verify if application sizes influence the rating. A marginal plot is a scatterplot that has histograms, boxplots, or dotplots in the margins of the x- and y-axes.

```{r size-rating-plot}
#Marginal plot of size vs rating
plot <- clean_play_store %>%
  ggplot(aes(x = size_mb, y = rating, na.rm = TRUE)) + #na.rm removes NA values
  geom_point(color = custom_cols("blueish green"), na.rm = TRUE) +
  labs(
    title = "Marginal Plot",
    subtitle = "Size Vs Rating",
    y = "Rating",
    x = "Size (MB)",
    caption = "Source: google play store dataset"
  )

#Marginal plot
ggMarginal(
  plot,
  type = "histogram",
  fill = custom_cols("blueish green"),
  alpha = 0.6
)
```

**Finding:** We observed that majority of applications with sizes under 25 MB have a good rating (above 4).


## Exploring installs column
### Number of installs per category
```{r installs-percategory}

#Bar plot of installs vs category
clean_play_store %>%
  count(category, installs, types) %>%
  #group by category and types column
  group_by(category, types) %>%
  summarize(totalInstalls = sum(as.numeric(installs))) %>% #calculating the total number of installs
  head(33) %>%
  ggplot(aes(
    x = reorder(category, totalInstalls),
    y = log(totalInstalls), #log transforming because the values range till a billion
    fill = types
  )) +
  #setting the bar width to 0.5
  geom_bar(width = 0.5, stat = "identity") +
  #formating the label
  scale_y_continuous(labels = scales::comma) +
  labs(
    title = "Bar Chart",
    subtitle = "Number of Installs per Category",
    x = "Category",
    y = "Number of Installs(log)",
    caption = "Source: google play store dataset"
  ) +
  scale_fill(palette = "main") +
  theme(axis.text.x = element_text(angle = 0)) +
  #flipping the coordinate
  coord_flip()
```

**Finding:** The graph shows the log of number of installs (the values of installs varied from 0 to 1 billion) vs CATEGORY. FAMILY and GAME have the highest number of installs. EVENTS, HOUSE_AND_HOME, COMICS, LIBRARIES_AND_DESIGN and BEAUTY have the least number of installs.

### Top 10 installed categories  

```{r top10-installed-categories}
#Top 10 categories with most number of installs
clean_play_store %>%
  count(category, installs) %>%
  group_by(category) %>%
  summarize(totalInstalls = sum(as.numeric(installs))) %>%
  #arranging in desc order of totalinstalls to get the top installed categories
  arrange(-totalInstalls) %>%
  #taking the top 10
  head(10) %>%
  #Bar plot of category vs total installs
  ggplot(aes(
    x = reorder(category, -totalInstalls),
    y = totalInstalls/1000000,
    fill = custom_cols("red")
  )) +
  geom_bar(width = 0.5,
           fill = custom_cols("blueish green"),
           stat = "identity") +
  labs(
    title = "Bar Chart",
    subtitle = "Top 10 Installed Categories",
    x = "Category",
    y = "Number of Installs(Million)",
    caption = "Source: google play store dataset"
  ) +
  #changing the format of labels of installs
  scale_y_continuous(labels = scales::comma) +
  theme(axis.text.x = element_text(angle = 360, vjust = 0.5),
        legend.position = "None") +
  #flip the coordinate
  coord_flip()
```

**Finding:** The apps under Communicationcategory have more than 1500M number of installs. 

### 10 least installed categories
```{r bottom10-installed-categories}
clean_play_store %>%
  count(category, installs) %>%
  group_by(category) %>%
  #computing the total number of installs
  summarize(totalInstalls = sum(as.numeric(installs))) %>%
  #arranging the dataset in descending order of totalInstalls
  arrange(-totalInstalls) %>%
  #taking the last 10 records
  tail(10) %>%
  ggplot(aes(x = reorder(category, totalInstalls), y = totalInstalls/1000000)) +
  geom_bar(width = 0.5,
           fill = custom_cols("vermillion"),
           stat = "identity") +
  labs(
    title = "Bar Chart",
    subtitle = "10 Least Installed Categories",
    x = "Category",
    y = "Number of Installs(Million)",
    caption = "Source: google play store dataset"
  ) +
  scale_y_continuous(labels = scales::comma) +
  theme(axis.text.x = element_text(angle = 0, vjust = 0.5),
        legend.position = "None") +
  #flipping the coordinate
  coord_flip()
```

**Finding:** We observed that applications under "Events" category have the least number of installed applications followed by medical and education categories. 

### Top 10 paid Categories
```{r top-paid-categories-plot}
#Top 10 categories with the highest number of installs for paid applications.
clean_play_store %>%
  filter(types == "Paid") %>% #filtering for paid apps
  group_by(category) %>%
  summarize(totalInstalls = sum(installs)) %>%
  arrange(desc(totalInstalls)) %>% #desc order of totalinstalls
  head(10) %>% #taking the first 10 records
  ggplot(aes(x = reorder(category, -totalInstalls) , y = totalInstalls/1000000)) +
  geom_bar(fill = custom_cols("blueish green"),
           stat = "identity",
           width = 0.5) +
  labs(
    title = "Bar Chart",
    subtitle = "Top 10 Paid Categories",
    x = "Category",
    y = "Number of Installs(Million)",
    caption = "Source: google play store dataset"
  ) +
  scale_y_continuous(labels = scales::comma) +
  theme(axis.text.x = element_text(angle = 65, vjust = 0.5),
        legend.position = "None") 
```

**Finding:** Applications with family and game category with 20M installs have the highest number of installs.

### Size Vs. number of installs    
Size is an important characteristic of an application. Large applications might reduce the number of installs, as it reduces to targeted audience. We can test this by plotting size against installs. 
```{r size-installs-plot}

plot <- clean_play_store %>%
  filter(!is.na(size_mb)) %>% #removing NA values
  ggplot(aes(
    x = size_mb,
    y = log(installs + 0.005),
    na.rm = TRUE
  )) +
  geom_point(color = custom_cols("vermillion"), na.rm = TRUE) +
  labs(
    title = "Marginal Plot",
    subtitle = "Size Vs Number of Installs",
    y = "No. of Installs (Log)",
    x = "Size (MB)",
    caption = "Source: google play store dataset"
  )
#marginal plot
ggMarginal(plot,
           type = "histogram",
           fill = custom_cols("vermillion"),
           alpha = 0.6)
```

**Finding:** Optimally sized applications with sizes between 5MB and 30MB have the greatest number of installs. 


### Number of installs based on support by minimum android version
```{r android_ver,warning=FALSE,message=FALSE}
#Bar plot of min android version vs types
clean_play_store %>%
  ggplot(aes(x = min_android_ver, fill = types)) +
  geom_bar(width = .5,
           alpha = 0.7,
           na.rm = TRUE) +
  labs(
    title = "Bar Chart",
    subtitle = "Installs Based on Min. Android Version",
    x = "Min. Android Version",
    y = "Count",
    caption = "Source: google play store dataset",
    fill = "Types"
  ) +
  theme(
    legend.title = element_text(hjust = 0.5, face = "bold", size = 10),
    axis.text.x = element_text(angle = 90)
  )
```

**Finding:** 4.1 android version has the maximum number of installs. This implies that most google play store users use a minimum of 4.1 android version.

\newpage

# Summary of EDA
 + To get most success from an app, it has to have maximum number of reviews and maximum number of ratings. These are the other trends we found:  
   1) Apps should atleast support 4.1 android version or more to succeed.This is expected because the majority of users have smart phones with constant android updates.  
   2) They have high chances of success if the genre is family, game, communication or productivity apps whereas food_and_drink, auto_vehicles categories have very low probability to succeed.  
   3) The apps which are be free have huge success rates however there are a few exceptions to this.  
   4) Apps should be optimally sized between 5MB and 30MB.  



# Future work (models)  
## What are we trying to achieve (thesis/hypothesis)
The dataset contains information about ten thousand apps dated till the year 2018. We plan on using Linear Regression Model, Recursive Partitioning Model and Random Forest Model to perform predictive analysis. We want to answer the following hypothesis:  

1) Find similarities in apps that make it to the top of Play Store. Factors contributing to the success of applications.
2) Can we predict rating of apps based on other parameters such as number of reviews or the size of an app?

To answer these questions, we will be exploring all the variables of this dataset to find if there's any relationship between rating and other variables. We intend to find out which of these variables will play the most important role in predicting rating.
 

## Why is this important/interesting?
Before we started this project, we took part in a competition called game-jam [12] where we built a game,we had an idea of launching it on Google Play Store.We then thought it would be interesting to see currents trends in the market and to do a detailed analysis to get more insights to the following questions:  
1.Factors that influence the success of an app,    
2.Which categories are highly installed    
3.What are the most famous applications and do they have any trends in common like number of installs, number of reviews, size or android-version? and etc  

This analysis inturn will aid the developer community to build successful apps targeting a specific audience.


## How are we going to test the hypothesis?
Since the dataset is dated till 2018.  We are thinking to test it by comparing the predictions of our model with the 2019 dataset if possible or we will test our model with dummy application 


## Any challenges that we might encounter
We cannot ensure complete accuracy of the model because there is a lot of useful information missing that could have given us more insight into the Google Play Store market e.g. Demographic data could have offered insights into the rating and number of installs of apps, with respect to different regions,  different cultures and different trends popular to specific age groups. Also, it would have been interesting to see how different global trends affect the usage of the app, for instance, the current pandemic "covid-19" has called for quarantine across the globe and many people, markets and other companies are relying on smart phones and virtual connections, this will heavily increase the use of many applications, thus deviating from the general trend. 

# Models
 + The goal is to predict the rating of an application based on different parameters. Our EDA confirms that variables like number of installs, number of reviews, category of the app and the type of app (paid/free) can affect the rating of an app.  

 + In this section,firstly, we tried to fit our dataset for both explanatory and predictive models. We used the cross-validation technique to select the best fitting model for our dataset and lastly, we test the models by predicting ratings for a dummy app.

## Correlation using Pearson method
 + The bivariate Pearson correlation indicates whether a statistically significant linear relationship exists between two continuous variables or it indicates the strength of a linear relationship (i.e., how close the relationship is to being a perfectly straight line)

 + Before creating a model, we calculated the correlation between different variables to help us select appropriate exploratory variables.
```{r correlation_rating_installs}

# Finding Correlation between rating and installs column
cor_rat_ins <- cor(
  clean_play_store$installs,
  clean_play_store$rating,
  use = "complete.obs" ,
  method = "pearson"
)
names (cor_rat_ins) <- "Rating and Installs"


# Finding Correlation between rating and log10(installs)^2
cor_rat_ins_transformed <- cor(
  log10(clean_play_store$installs) ^ 2,
  clean_play_store$rating ,
  use = "complete.obs",
  method = "pearson"
)

names(cor_rat_ins_transformed) <- "Rating and Installs(transformed)"

# print out both values
knitr::knit_print(cor_rat_ins)
knitr::knit_print(cor_rat_ins_transformed)

```
+ **Correlation coefficient between rating and installs**: The correlation coefficient is 0.0402. This indicates a slight positive relation between these two variables. Using square of log of installs, increased the correlation coefficient to 0.1138.

 
```{r correlation_rating_reviews}

# Finding Correlation between rating and reviews
cor_rat_rev <- cor(
  clean_play_store$reviews,
  clean_play_store$rating,
  use = "complete.obs",
  method = "pearson"
)

names(cor_rat_rev) <- "Rating and Reviews"

# Finding Correlation between rating and log10(reviews)^2
cor_rat_rev_transformed <- cor(
  log10(clean_play_store$reviews) ^ 2,
  clean_play_store$rating ,
  use = "complete.obs",
  method = "pearson"
)

names(cor_rat_rev_transformed) <- "Rating and Reviews(transformed)"

# print out both values
knitr::knit_print(cor_rat_rev)
knitr::knit_print(cor_rat_rev_transformed)

```
 + **Correlation coefficient between rating and reviews**: The correlation coefficient is 0.05515, indicating a slight positive relationship between the two variables. Using square of log of installs, increased the correlation coefficient to 0.20308.
 
\newpage
 
## Explanatory/Descriptive modeling
* The following models are used: 
 + Linear Regression Model
 + Local Regression Model
 + Recursive Partitioning Model

```{r descriptive_modeling_1, warning=FALSE, message=FALSE,fig.show='hold',fig.align='center'}
# Turn off scientific notation
options(scipen = 999)

# Function for creating jitter plot
jitterPlot <- function(x_var) {
  if (x_var == "installs") {
    x_axis_label <- "Installs(log10^()2 transformed)"
    var_selected <- log10(clean_play_store$installs) ^ 2
    
  } else if (x_var == "size_mb") {
    x_axis_label <- "Size(log10 transformed)"
    var_selected <- log10(clean_play_store$size_mb)
    
  } else if (x_var == "reviews") {
    x_axis_label <- "Reviews(log10^()2 transformed)"
    var_selected <- log10(clean_play_store$reviews) ^ 2
  }
  
  #Jitter plot of selected variable vs rating for rpart, loess and lm models
  clean_play_store %>%
    ggplot(aes_string(x = var_selected, y = "rating")) +
    scale_x_log10() + #log 10 transformation
    geom_jitter(na.rm = TRUE,
                color =  custom_cols("blueish green"),
                alpha = .4) +
    geom_smooth(
      method = "rpart",
      se = FALSE,
      aes(color = "orange"),
      na.rm = TRUE
    ) +
    geom_smooth(method = "loess",
                se = FALSE,
                aes(color = "red"),
                na.rm = TRUE) +
    geom_smooth(method = "lm",
                se = FALSE,
                aes(color = "blue"),
                na.rm = TRUE) +
    labs(
      title = "Jitter Plot",
      subtitle = paste (x_axis_label, "vs Rating", collapse = " "),
      x = x_axis_label,
      y = "Rating",
      caption = "Source: google play store dataset"
    ) +
    theme(legend.title = element_text(
      hjust = 0.5,
      face = "bold",
      size = 10
    )) +
    scale_color_manual(
      name = 'Models',
      values = c(
        "orange" = "orange",
        "red" = "red",
        "blue" = "blue",
        "vermillion"
      ),
      labels = c(
        "Linear Regression Model",
        "Recursive Partitioning Model",
        "Local Regression Model"
      )
    )
}

jitterPlot("installs") # Creating a jitter plot: installs vs rating
jitterPlot("size_mb") # Creating a jitter plot: size_mb vs rating
jitterPlot("reviews") # Creating a jitter plot: reviews vs rating
```

The graphs above show the fitted Linear Regression model, Local Regression model and Recursive Partitioning model for predicting rating using number of installs, size of the app and number of reviews variables. 


## Explanatory/Descriptive modeling (cont.) 
Continuing with our explanatory modeling, we will fit a model for rating vs installs given taking into consideration whether the app is Free or Paid.  We have also calculated sum of square residuals, R-Square value and Root Mean Square Error for the model. 
```{r descriptive_modeling_2}

# Fitting a lm model
model_rat_instl <-
  lm(rating ~ installs + types + category + reviews, data = clean_play_store)


# Getting Regression points table
points_table <- get_regression_points(model_rat_instl)

points_table

# Fitting a model taking into consideration the type of app(Free or Paid)
points_table %>%
  ggplot(aes(x = log10(installs + .0005), y = rating)) +
  geom_jitter(na.rm = TRUE,
              color =  custom_cols("sky blue"),
              alpha = .4) +
  geom_smooth(aes(color = types), method = "lm", se = FALSE) +
  labs(
    title = "Jitter Plot",
    subtitle = "Log10(Installs) vs Rating",
    x = "Log10(Installs)",
    y = "Rating",
    color = "Types",
    caption = "Source: google play store dataset"
  ) +
  theme(legend.title = element_text(hjust = 0.5, face = "bold", size = 10))

# Calculating Sum of Square residuals
points_table %>%
  summarise(square = sum(residual ^ 2))

# Calculating R-Squared to values
points_table %>%
  summarise(r_squared = 1 - var(residual) / var(rating))

# Calculating RMSE
points_table %>%
  summarise(RMSE = sqrt(mean(residual ^ 2)))

```
**Observations/Findings**: We observe that the rating of paid apps is higher than the free apps indicating better quality of paid apps. On the other hand, free apps have a higher number of installs, thus covering a wide range of audience.



## Cross Validation of models
This technique helps us identify the best fit model for our dataset i.e. model with the least root mean square error
```{r cross_validation, warning=FALSE,message=FALSE}

# Spliting our dataset into two dattasets i.e. train(75%) and test(25%)
smp_size <- floor(0.75 * nrow(clean_play_store))

train_ind <-
  sample(seq_len(nrow(clean_play_store)), size = smp_size)
train <- clean_play_store[train_ind,]
test <- clean_play_store[-train_ind,]

# Fitting our models, Linear Regression model and Recursive Partitioning model
model_lm_rat_instl <-
  lm(rating ~ installs + types + category + reviews, data = train)
model_rpart_rat_inst <-
  rpart(rating ~ installs + types + category + reviews , data = train)

# Predicting rating for test dataset
predicted_rating_lm <- predict(model_lm_rat_instl, newdata = test)
predicted_rating_rpart <-
  predict(model_rpart_rat_inst, newdata = test)

# Calculating error
error_lm <- test$rating - predicted_rating_lm
error_rpart <- test$rating - predicted_rating_rpart

# Calculating Root Mean Square Error
RMSE_lm <- sqrt(mean(error_lm ^ 2, na.rm = TRUE))
RMSE_rpart <- sqrt(mean(error_rpart ^ 2, na.rm = TRUE))

#Making a dataframe to compare the models
model <- c('Linear regression model','Recursive partitioning model')
RMSE <- (c(RMSE_lm,RMSE_rpart))
model_compare <- data.frame(model, RMSE)

model_compare %>%
  kable(caption = "Comparision of models")
 
```
  + We sliced the dataset into training and test datasets. Training dataset contain 6,951 observations (75% of total) and test data set contains 2,198 observations (25% of total). 
  + We trained both Linear Regression model (lm) and Recursive Partitioning model (rpart) with the training dataset.
  + After training our model, we predicted the rating for test dataset. In order to find which model fits better, we calculated the root mean square error (RMSE) for both models. RMSE values for Linear Regression model and Recursive Partitioning model are 0.5277467 and 0.5183104 respectively. We can see that RMSE value for Recursive Partitioning model is less than RMSE value for Linear Regression model implying that Recursive Partitioning model can make a better prediction than Linear Regression model. 
  + Along with performing a comparison between Linear Regression model and Recursive Partitioning model, we experimented with different explanatory variables for each model. We got the least RMSE by using installs, types, categories and reviews as explanatory variables.

## Making Predictions 
We can predict ratings for an application with the help of parameters like installs, types, category and reviews. We choose applications from Google Play Store and used their number of installs, reviews, type and category to calculate their rating. We will compare this rating with the existing rating of the application. We will perform this experiment for three applications, to see how close the calculated values are to the original values. 
```{r predictive_modeling, warning=FALSE,message=FALSE}

#code below:create a function to predict rating when the inputs are given
predict_rating <- function(installs,type,category,reviews){
  #construct a predict dataset based on the inputs
  predict_app <-
  data.frame(
    "installs" = installs,
    "types" = type,
    "category" = category,
    "reviews" = reviews
  )
#Use recursive partitioning model to predict the ratings
predicted_rating_rpart <-
  predict(model_rpart_rat_inst, newdata = predict_app)
#return the predicted rating value
 predicted_rating_rpart
}

#App1: Nike Training Club - Workouts & Fitness Guidance (data from [6])
#Actual rating: 4.2
predict_rating(
    installs = 100000000,
    type = "Free",
    category = "HEALTH_AND_FITNESS",
    reviews = 272000
  )

#App2: Wedding Planner & Organizer, Guest Checklists (data from [6])
#Actual rating:4.5
predict_rating(
    installs = 10000,
    type = "Free",
    category = "EVENTS",
    reviews = 220
  )
```
 + We chose the "Nike Training Club - Workouts & Fitness Guidance" application for our first experiment. It has 10 million downloads. It belongs to HEALTH_AND_FITNESS category and is reviewed by 272000 users. The actual value of it's rating is 4.2. We used this information to calculate the rating of this app. The Recursive Partitioning Model predicted the rating to be 4.28 which is close to the actual value. 
 + The second application we chose is "Wedding Planner & Organizer, Guest Checklists". It has 10000 installs with 220 reviews. It is Free app and, belongs to EVENTS category. Its actual rating is 4.5. Our model calculated its rating to be 2.13. This is a considerable difference. We observed that for values that are on either extreme i.e. too low or too high, the model does not perform well. In this case, the number of reviews is very less.  
 


# Conclusion
 + We have found that recursive partitioning model predicts ratings better than linear regression model with RMSE 0.51 and 0.52 respectively. 
 + We found that our model's accuracy is better if the rating is 4 or more. This is because the majority of the dataset has ratings more than 4 which is evident from the density plot of rating which was highly left-skewed.
 + The recursive partitioning model does not perform well with extreme values.


\newpage

# References

[1] [Dataset](https://www.kaggle.com/lava18/google-play-store-apps);  
[2] [R markdown](https://bookdown.org/yihui/rmarkdown/html-document.html#tabbed-sections) ;  
[3] [Stackoverflow](https://stackoverflow.com/questions/3993301/how-to-format-number-values-for-ggplot2-legend/15007117) ;  
[4] [GGally](https://ggobi.github.io/ggally/rd.html#ggpairs);  
[5] [Custom color pallete](https://drsimonj.svbtle.com/creating-corporate-colour-palettes-for-ggplot2);   
[6] [App details] (https://play.google.com/store/apps);
[7] [Colors](https://hbr.org/2014/04/the-right-colors-make-data-easier-to-read);  
[8] [TidyVerse](https://www.tidyverse.org/);  
[9] [ggplot2](https://ggplot2.tidyverse.org/reference/);  
[10] [Google playstore Kernel by Danilodiogo](https://www.kaggle.com/danilodiogo/google-play-store-eda-plotting-with-highcharts/code#eda);  
[11] [market share](https://gs.statcounter.com/os-market-share/mobile/worldwide) ;  
[12] [Global game jam](https://globalgamejam.org/) ;  
[13] [Play Store Statistics](https://www.statista.com/statistics/266210/number-of-available-applications-in-the-google-play-store/) ; 
